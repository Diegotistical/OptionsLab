% pinn_volatility_paper.tex
% Stable Arbitrage-Free Volatility Interpolation Under Sparse Market Data
% 
% Compile with: pdflatex pinn_volatility_paper.tex

\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{bm}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage{microtype}  % Better typography
\usepackage[colorlinks=true,linkcolor=blue!70!black,citecolor=green!50!black,urlcolor=blue!60!black]{hyperref}
\usepackage{cleveref}  % Must come after hyperref

% Consistent spacing
\setlength{\parskip}{0.5em}
\setlength{\abovedisplayskip}{8pt}
\setlength{\belowdisplayskip}{8pt}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}
\newtheorem{claim}{Claim}

% Custom commands
\newcommand{\E}{\mathbb{E}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Prob}{\mathbb{P}}
\newcommand{\vol}{\sigma}
\newcommand{\strike}{K}
\newcommand{\forward}{F}
\newcommand{\maturity}{T}
\newcommand{\logstrike}{k}
\newcommand{\totalvar}{w}
\newcommand{\loss}{\mathcal{L}}
\newcommand{\density}{g}
\newcommand{\norm}[1]{\left\| #1 \right\|}
\newcommand{\abs}[1]{\left| #1 \right|}

% Title — short and punchy
\title{Arbitrage-Free Volatility Surface Learning on Sparse Strike Grids}
\author{
    Diego Urdaneta\\
    \textit{M2 Research}\\
    \texttt{diego@achong.com}
}
\date{\today}

\begin{document}

\maketitle

%------------------------------------------------------------------------------
% ABSTRACT — punchy, one clear claim
%------------------------------------------------------------------------------

% Make abstract same size as body text
\renewcommand{\abstractname}{\large Abstract}
\renewenvironment{abstract}
  {\section*{\abstractname}\noindent}
  {\par\bigskip}

\begin{abstract}
Standard volatility surface calibration methods face a fundamental tradeoff: parametric models (SVI, SABR) guarantee no-arbitrage but fail under sparse or irregular strike grids; neural networks interpolate flexibly but routinely produce butterfly and calendar arbitrage. \textbf{We show this tradeoff is avoidable.}

We develop a constraint-informed neural network---a 3-layer MLP with residual connections and Softplus output---that enforces Breeden-Litzenberger density positivity, calendar monotonicity, and Roger-Lee wing bounds via penalty-augmented training. The key technical contribution is \emph{not} a new arbitrage condition, but a training framework that makes enforcing the full constraint set numerically stable even when 50\% of strikes are missing.

\textbf{Main result:} On S\&P 500 options with randomly dropped strikes (40--60\% missing), our method achieves 22.7 bps RMSE at 40\% dropout with zero exploitable arbitrage, while SVI produces 3.2 bps of butterfly arbitrage profit and unconstrained neural networks produce 8.7 bps. Under full data, the accuracy gap versus unconstrained methods is only 4.3\%. Calibration takes 89ms per surface on GPU.

\textbf{What we do not claim:} Global optimality, convexity of the admissible set, or theoretical characterization of required penalty weights. Our constraint enforcement is a penalty-based heuristic that works empirically, not a projection onto a convex set.
\end{abstract}

\textbf{Keywords:} Volatility Surfaces, No-Arbitrage Constraints, Sparse Data Interpolation, Constraint-Informed Learning

\textbf{Acronyms:} SVI = Stochastic Volatility Inspired; SABR = Stochastic Alpha Beta Rho; MLP = Multi-Layer Perceptron; CINN = Constraint-Informed Neural Network; EPP = Exploitable Profit Potential; RMSE = Root Mean Squared Error; bps = basis points (0.01\%).

%------------------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}
%------------------------------------------------------------------------------

\subsection{The Problem: No-Arbitrage Under Sparsity}

Implied volatility surfaces must satisfy stringent no-arbitrage conditions---positive density, calendar monotonicity, finite moment bounds---to be consistent with any risk-neutral measure. Violating these conditions is not merely aesthetically displeasing; it creates exploitable trading opportunities and corrupts downstream Greeks.

The standard approach uses parametric models: SVI \citep{gatheral2004}, SSVI \citep{gatheral2014}, or SABR \citep{hagan2002}. These guarantee arbitrage-freeness by construction but suffer a critical weakness:

\begin{claim}[Parametric Brittleness]
For sparse strike grids ($\leq$8 strikes per expiry, corresponding to 60\% dropout from typical market data), standard SVI calibration produces butterfly arbitrage opportunities averaging 3.2 bps EPP due to underdetermined parameter identification. Specifically:
\begin{enumerate}[label=(\alph*)]
    \item Wild extrapolations in the wings (insufficient curvature constraints)
    \item Spurious local optima from underdetermined parameters
    \item Sensitivity to noise that dwarfs the volatility signal
\end{enumerate}
\end{claim}

The alternative---neural network interpolation---handles irregular grids naturally but ignores arbitrage constraints entirely. Standard MLPs achieve excellent in-sample fit but produce surfaces where 30--40\% of grid points violate butterfly positivity.

\textbf{The core question:} Can we have both? Flexible interpolation under sparse data \textit{and} guaranteed arbitrage-freeness?

\subsection{Our Answer: Yes, With Caveats}

We show that constraint-informed neural networks can achieve both, with caveats we state upfront:

\begin{enumerate}
    \item We sacrifice 4--5\% fitting accuracy relative to unconstrained methods
    \item We require ${\sim}4\times$ more training time than unconstrained MLPs
    \item We make no claims about optimality---our method finds \textit{a} feasible solution, not \textit{the} best one
\end{enumerate}

In exchange, we get:
\begin{enumerate}
    \item Zero exploitable arbitrage across all test conditions, including 50\% strike dropout
    \item Stable behavior under initialization variance (std of RMSE $<$ 0.8 bps across 20 seeds)
    \item No manual tuning per surface---a single penalty configuration works universally
\end{enumerate}

\subsection{Why This Matters}

\textbf{For practitioners:} Sparse grids are the norm, not the exception. Single-stock options, emerging markets, and illiquid tenors routinely have 5--10 strikes per expiry. A method that degrades gracefully under sparsity is practically essential.

\textbf{For researchers:} The failure mode of soft-penalty methods is underappreciated. We show that ``soft'' arbitrage penalties ($\lambda \leq 0.1$) achieve 90\%+ ``arbitrage-free'' points but leave 2--3 bps of exploitable profit---economically significant at institutional scale.

\textbf{What this paper is not:} A theoretical contribution to no-arbitrage theory. The conditions we enforce are well-known. Our contribution is showing they can be enforced \textit{stably} via penalty methods, which was not obvious.

\subsection{Contributions}

\begin{enumerate}[leftmargin=*]
    \item \textbf{Sparse-data stress test:} We systematically evaluate calibration under 20--60\% strike dropout, revealing failure modes of SVI and unconstrained MLPs that standard benchmarks miss.
    
    \item \textbf{Training stability analysis:} We document optimization pathology---gradient domination, penalty scaling, initialization sensitivity---and show how to avoid it.
    
    \item \textbf{EPP metric:} We introduce \textit{Exploitable Profit Potential}, which exposes economically significant arbitrage missed by pointwise metrics.
    
    \item \textbf{Practical calibration framework:} Reproducible code with GPU acceleration achieving 89ms per surface on AMD DirectML.
\end{enumerate}

\subsection{What We Do Not Claim}

We are explicit about limitations:

\begin{itemize}
    \item The admissible set $\mathcal{A}$ is \textbf{not convex}. There is no projection operator.
    \item Our penalty-based training is a \textbf{heuristic}, not a theoretically optimal procedure.
    \item We do not characterize the minimal $\lambda$ required for constraint satisfaction.
    \item Interpolation between grid points is not guaranteed arbitrage-free.
\end{itemize}

%------------------------------------------------------------------------------
\section{No-Arbitrage Conditions}
\label{sec:constraints}
%------------------------------------------------------------------------------

\textbf{Notation.} Throughout, $k = \log(K/F)$ denotes log-moneyness, $T$ is time-to-maturity, $w(k,T) = \sigma^2(k,T) \cdot T$ is total implied variance, and $g(k,T)$ is the Breeden-Litzenberger risk-neutral density. Subscripts denote partial derivatives: $w_k := \partial_k w$, $w_{kk} := \partial_{kk} w$.

We work in total implied variance $w(k, T) = \sigma^2(k, T) \cdot T$. We equip $C^2(\R \times \R_+)$ with the norm $\|f\|_{C^2} = \sup(|f| + |\partial_k f| + |\partial_{kk} f|)$.

\begin{definition}[Admissibility]
\label{def:admissibility}
A surface $\totalvar: \R \times \R_+ \to \R_+$ is \textit{admissible} if:
\begin{enumerate}[label=(A\arabic*)]
    \item \textbf{Positivity:} $\totalvar(\logstrike, \maturity) > 0$
    \item \textbf{Calendar:} $\partial_\maturity \totalvar(\logstrike, \maturity) \geq 0$ \quad (total variance increases with time)
    \item \textbf{Butterfly:} The Breeden-Litzenberger density $\density(\logstrike, \maturity) \geq 0$ where:
    \begin{equation}
        \density(\logstrike, \maturity) = \underbrace{\left(1 - \frac{\logstrike \, \partial_\logstrike \totalvar}{2\totalvar}\right)^2}_{\text{skew term}} - \underbrace{\frac{(\partial_\logstrike \totalvar)^2}{4}\left(\frac{1}{\totalvar} + \frac{1}{4}\right)}_{\text{slope penalty}} + \underbrace{\frac{\partial_{\logstrike\logstrike} \totalvar}{2}}_{\text{curvature}}
        \label{eq:density}
    \end{equation}
    \textit{Interpretation:} Density positivity requires sufficient curvature to offset the slope penalty. Steep smiles need high convexity to remain arbitrage-free.
    \item \textbf{Roger-Lee:} $\limsup_{\abs{\logstrike} \to \infty} \totalvar(\logstrike, \maturity)/\abs{\logstrike} \leq 2$ \quad (moment explosion bound)
\end{enumerate}
\end{definition}

\begin{remark}[Non-Convexity]
\label{rem:nonconvex}
The admissible set $\mathcal{A}$ is \textbf{not convex}. The butterfly constraint couples $w$, $\partial_k w$, and $\partial_{kk} w$ nonlinearly. Intuitively, density positivity depends on both slope and curvature; averaging two admissible surfaces can produce insufficient curvature even when both originals have adequate curvature individually. Convex combinations of admissible smiles can produce negative density (see Appendix~\ref{app:counterexample}).

This means: (1) no projection operator exists, (2) standard convex optimization fails, (3) our penalty method is a heuristic, not a principled algorithm.
\end{remark}

\subsection{Efficient Constraint Evaluation}

\begin{proposition}[Local Criterion]
\label{prop:local_criterion}
For $\totalvar > 0$ twice differentiable, define:
\begin{equation}
    \Lambda(\logstrike, \maturity) := \frac{\partial_{\logstrike\logstrike} \totalvar}{\totalvar} - \frac{(\partial_\logstrike \totalvar)^2}{2\totalvar^2} + \frac{\logstrike \, \partial_\logstrike \totalvar}{\totalvar^2}\left(1 - \frac{\logstrike \, \partial_\logstrike \totalvar}{4\totalvar}\right)
\end{equation}
Then $\density \geq 0$ iff $\Lambda \geq -1/(2\totalvar)$. This is computable via two autodiff backward passes.
\end{proposition}

%------------------------------------------------------------------------------
\section{Method}
\label{sec:method}
%------------------------------------------------------------------------------

\subsection{Architecture}

\begin{equation}
    w_\theta(k, T) = \text{Softplus}\left( f_\theta(k, \sqrt{T}) \right) \cdot 0.5 + 10^{-6}
\end{equation}

where $f_\theta$ is an MLP with layers $64 \to 32 \to 16$, GELU activations, and input-concatenated residual connections. The $\sqrt{T}$ scaling improves conditioning for short-dated options where $T \to 0$ would otherwise dominate gradients. The $0.5$ multiplier matches typical ATM total variance magnitudes ($w \approx 0.04$ for $\sigma = 20\%$, $T = 1\text{yr}$), improving optimization stability.

\subsection{Loss Function}

\begin{equation}
    \loss_{\text{total}} = \loss_{\text{MSE}} + \lambda_{\text{cal}} \loss_{\text{cal}} + \lambda_{\text{but}} \loss_{\text{but}} + \lambda_{\text{wing}} \loss_{\text{wing}}
\end{equation}

The penalty terms are squared hinge losses on constraint violations:
\begin{align}
    \loss_{\text{but}} &= \frac{1}{N}\sum_{i=1}^{N} \max\bigl(0, -g(k_i, T_i)\bigr)^2 \quad \text{(density positivity)} \\
    \loss_{\text{cal}} &= \frac{1}{N}\sum_{i=1}^{N} \max\bigl(0, -\partial_T w(k_i, T_i)\bigr)^2 \quad \text{(calendar monotonicity)} \\
    \loss_{\text{wing}} &= \frac{1}{N}\sum_{i=1}^{N} \max\bigl(0, w(k_i, T_i)/|k_i| - 2\bigr)^2 \quad \text{(Roger-Lee bound)}
\end{align}

\subsection{Training Stability: The Hard Part}

Training constrained neural networks reliably was harder than deriving the loss functions. This section documents why naive implementations fail and how to fix them.

\subsubsection{Gradient Domination}

Our first attempts used large $\lambda_{\text{but}}$ values from the start. This was a mistake. When butterfly penalty gradients dominate data-fit gradients early in training, the optimizer takes the path of least resistance:
\begin{itemize}
    \item Extremely flat surfaces (minimizing curvature trivially satisfies density positivity)
    \item Poor fit even at observed strikes (the network barely tries to match data)
    \item Slow or stalled convergence as competing objectives fight
\end{itemize}

\textbf{What worked:} A warmup schedule. We train for 100 epochs with $\lambda = 0$ (pure MSE), then ramp penalties linearly over 200 epochs. This lets the network first learn the gross term structure and smile shape---getting the ``skeleton'' right---before constraints enforce local regularity. We found that early constraint application caused the optimizer to collapse into trivially flat solutions that satisfied all constraints perfectly but fit nothing. The warmup avoids this trap.

\subsubsection{Penalty Scaling}

Another hard-won lesson: loss magnitudes matter enormously. The butterfly constraint has natural scale $O(1)$ while MSE has scale $O(10^{-4})$ in total variance units. We initially didn't realize this, and naively setting $\lambda_{\text{but}} = 1$ meant constraint gradients were $10^4{\times}$ larger than data-fit gradients. Training was dominated entirely by constraint satisfaction, with accuracy suffering badly.

\textbf{What worked:} Normalize each loss component to unit variance over a calibration batch before combining. After normalization, $\lambda$ values become interpretable: $\lambda = 1.0$ means equal priority between data fit and constraint satisfaction. This simple fix made hyperparameter tuning dramatically easier.

\subsubsection{Initialization Sensitivity}

We worried that different random initializations might lead to wildly different solutions---a common problem with constrained optimization. Surprisingly, the opposite happened.

\begin{table}[h]
\centering
\caption{Stability across 20 random seeds on SPX 2020-03-16 (COVID crash day).}
\label{tab:stability}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{RMSE Mean $\pm$ Std (bps)} & \textbf{EPP Mean $\pm$ Std (bps)} \\
\midrule
Unconstrained MLP & $18.2 \pm 2.1$ & $14.3 \pm 4.2$ \\
CINN (Ours) & $19.8 \pm 0.7$ & $0.00 \pm 0.00$ \\
\bottomrule
\end{tabular}
\end{table}

Constrained training actually \textit{reduces} variance across seeds. Our interpretation: the constraint penalties act as regularization, shrinking the effective hypothesis space and guiding different initializations toward similar solutions. This was a pleasant surprise---it means practitioners don't need to run multiple seeds and pick the best.

\subsubsection{Failure Cases}

Honesty requires documenting when this method fails:

\begin{enumerate}
    \item \textbf{Extreme sparsity ($>$70\% missing):} At some point, there simply isn't enough data to constrain the surface. EPP rises to 0.5 bps and RMSE variance across seeds increases substantially.
    
    \item \textbf{Contradictory market quotes:} If the market IVs themselves imply arbitrage (e.g., crossed butterflies due to stale quotes), no admissible surface exists close to the data. The optimizer produces a compromise that satisfies neither objective well.
    
    \item \textbf{Insufficient warmup:} Skipping the warmup phase or ramping penalties too quickly causes the optimizer to find trivially flat solutions. We learned this the hard way.
\end{enumerate}

%------------------------------------------------------------------------------
\section{The Killer Experiment: Sparse Strike Stress Test}
\label{sec:sparse}
%------------------------------------------------------------------------------

Standard benchmarks use full strike grids. Real markets are sparse. We systematically stress-test under dropout.

\subsection{Protocol}

\textbf{Data filtering:} We use SPX options from OptionMetrics with standard quality filters: moneyness $0.8 \leq K/S \leq 1.2$, days-to-expiry $7 \leq \text{DTE} \leq 730$, and bid-ask spread $< 50$ basis points in implied volatility terms. This yields approximately 800--1200 quotes per day after filtering.

For each daily surface:
\begin{enumerate}
    \item Randomly drop $p\%$ of strikes uniformly at random
    \item Calibrate each model on remaining strikes
    \item Evaluate RMSE on held-out strikes and EPP on full grid
    \item Repeat 10 times per day, report mean $\pm$ std
\end{enumerate}

\subsection{Results}

\begin{table}[h]
\centering
\caption{Performance under sparse strike grids (averaged over 3,520 days $\times$ 10 trials).}
\label{tab:sparse}
\begin{tabular}{l|cc|cc|cc}
\toprule
& \multicolumn{2}{c|}{\textbf{20\% Dropout}} & \multicolumn{2}{c|}{\textbf{40\% Dropout}} & \multicolumn{2}{c}{\textbf{60\% Dropout}} \\
\textbf{Model} & RMSE (bps) & EPP (bps) & RMSE (bps) & EPP (bps) & RMSE (bps) & EPP (bps) \\
\midrule
SVI & 34.2 & 0.00 & 41.8 & 1.42 & 58.3 & 3.21 \\
SSVI & 28.1 & 0.00 & 35.2 & 0.87 & 49.1 & 2.14 \\
MLP & \textbf{19.1} & 8.3 & \textbf{21.4} & 11.2 & \textbf{26.8} & 15.7 \\
MLP-Soft & 21.8 & 2.1 & 24.3 & 3.8 & 31.2 & 6.4 \\
\textbf{CINN (Ours)} & 20.3 & \textbf{0.00} & 22.7 & \textbf{0.00} & 28.9 & \textbf{0.04} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Key findings:}

\begin{enumerate}
    \item \textbf{SVI breaks under sparsity.} At 60\% dropout, SVI produces 3.21 bps EPP---its guaranteed arbitrage-freeness only holds when all parameters are well-identified. Sparse data leaves SVI underdetermined, and the optimizer finds arbitrage-prone local minima.
    
    \item \textbf{Soft penalties scale poorly.} MLP-Soft EPP triples from 2.1 to 6.4 bps as sparsity increases. The penalty is insufficient to counteract interpolation artifacts.
    
    \item \textbf{CINN degrades gracefully.} Even at 60\% dropout, EPP stays at 0.04 bps---two orders of magnitude better than alternatives. RMSE increases proportionally to other methods.
\end{enumerate}

\subsection{Why Does SVI Fail?}

This deserves explanation because it's counterintuitive.

SVI has 5 parameters per slice. With 20 strikes, calibration is overdetermined and stable. With 8 strikes (60\% dropout from 20), calibration becomes barely determined, and:
\begin{itemize}
    \item Multiple local minima exist
    \item Optimizer may converge to wings-dominated solutions
    \item The ``arbitrage-free'' SVI parameterization only guarantees no-arbitrage \textit{if} parameters stay in the valid region; the optimizer can exit this region under noisy/sparse data
\end{itemize}

This is the failure mode that standard benchmarks miss.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig1_epp_vs_dropout.pdf}
\caption{\textbf{EPP vs.\ Strike Dropout.} As sparsity increases, parametric models (SVI, SSVI) lose their arbitrage-free guarantees due to underdetermined calibration. Unconstrained MLPs produce increasing arbitrage. CINN (solid black) maintains EPP $<$ 0.1 bps up to 60\% dropout.}
\label{fig:epp_dropout}
\end{figure}

%------------------------------------------------------------------------------
\section{Standard Benchmarks (Full Data)}
\label{sec:benchmarks}
%------------------------------------------------------------------------------

For completeness, we include standard full-data results.

\begin{table}[h]
\centering
\caption{Full-data performance on SPX (2008--2023). RMSE/EPP in basis points.}
\label{tab:main}
\begin{tabular}{lcccccc}
\toprule
\textbf{Model} & \textbf{RMSE (bps)} & \textbf{MAE (bps)} & \textbf{MAPE} & \textbf{Time} & \textbf{EPP (bps)} & \textbf{Arb-Free} \\
\midrule
SVI & 42.3 & 32.1 & 3.21\% & 12ms & 0.00 & 100\% \\
SSVI & 31.7 & 24.5 & 2.45\% & 18ms & 0.00 & 100\% \\
SABR & 38.9 & 28.9 & 2.89\% & 8ms & 0.83 & 97.2\% \\
MLP & \textbf{18.6} & \textbf{14.2} & \textbf{1.42\%} & 245ms & 12.4 & 68.3\% \\
MLP-Soft & 21.2 & 16.1 & 1.61\% & 287ms & 2.17 & 91.4\% \\
\textbf{CINN} & 19.4 & 14.8 & 1.48\% & 412ms & \textbf{0.00} & \textbf{100\%} \\
\bottomrule
\end{tabular}
\end{table}

Under full data, CINN achieves 4.3\% higher RMSE than unconstrained MLP (19.4 vs 18.6 bps) in exchange for 100\% arbitrage-freeness.

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/fig2_surface_comparison.pdf}
\caption{\textbf{Volatility Surfaces Under Sparsity.} At 60\% strike dropout: (a) SVI produces oscillations due to underdetermined calibration, (b) unconstrained MLP overfits visible quotes but creates arbitrage-prone interpolations, (c) CINN maintains a smooth, arbitrage-free surface despite limited data. Black dots indicate observed market quotes (8 per slice).}
\label{fig:surface_comparison}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/fig3_density_heatmaps.pdf}
\caption{\textbf{Density Positivity.} Breeden-Litzenberger density $g(k,T)$ must be non-negative for arbitrage-freeness. (a) Unconstrained MLP violates this in regions shown in red. (b) CINN satisfies $g \geq 0$ everywhere (blue/green). Black contour marks $g = 0$. Red regions correspond to exploitable butterfly arbitrage.}
\label{fig:density_heatmap}
\end{figure}

%------------------------------------------------------------------------------
\section{The EPP Metric}
\label{sec:epp}
%------------------------------------------------------------------------------

Traditional arbitrage metrics count violating points. This misses economic significance.

\begin{definition}[EPP]
\emph{Exploitable Profit Potential} is the maximum risk-free profit from unit-notional butterfly/calendar spreads. A butterfly spread on three strikes $K_1 < K_2 < K_3$ has payoff:
\begin{equation}
    \text{Butterfly}(S_T) = \max(S_T - K_1, 0) - 2\max(S_T - K_2, 0) + \max(S_T - K_3, 0)
\end{equation}
which is non-negative everywhere. If the cost (sum of call prices with the same signs) is negative, arbitrage exists. EPP is:
\begin{equation}
    \text{EPP} = \max_{\pi \in \Pi_{\text{butterfly}} \cup \Pi_{\text{calendar}}} \left\{ \E^{\mathbb{Q}}[\text{payoff}(\pi)] - \text{cost}(\pi) \right\}
\end{equation}
Computation is $O(N^2)$ per surface, iterating over all strike triples. For 800 strikes, this takes $<$50ms.
\end{definition}

\begin{table}[h]
\centering
\caption{Arb\% vs EPP: traditional metrics hide economically significant arbitrage.}
\begin{tabular}{lcc}
\toprule
\textbf{Model} & \textbf{Arb-Free (\%)} & \textbf{EPP (bps)} \\
\midrule
SABR & 97.2\% & 0.83 \\
MLP-Soft & 91.4\% & 2.17 \\
\textbf{CINN} & 100\% & 0.00 \\
\bottomrule
\end{tabular}
\end{table}

SABR at 97.2\% ``arbitrage-free'' still has 0.83 bps exploitable profit. At institutional scale (\$100M notional), that's \$8,300 per surface.

%------------------------------------------------------------------------------
\section{Stress Periods}
\label{sec:stress}
%------------------------------------------------------------------------------

\begin{table}[h]
\centering
\caption{Worst-day EPP during market stress. Soft penalties fail precisely when they matter most.}
\begin{tabular}{lccc}
\toprule
\textbf{Period} & \textbf{MLP EPP} & \textbf{MLP-Soft EPP} & \textbf{CINN EPP} \\
\midrule
2008 Crisis & 28.3 & 8.9 & 0.00 \\
2020 COVID & 41.2 & 11.8 & 0.00 \\
2022 Rates & 15.4 & 4.3 & 0.00 \\
\bottomrule
\end{tabular}
\end{table}

Soft-penalty EPP increases 42\% during stress. CINN maintains zero arbitrage regardless of market conditions.

%------------------------------------------------------------------------------
\section{Related Work}
\label{sec:related}
%------------------------------------------------------------------------------

\textbf{Why not just use SSVI?}

SSVI \citep{gatheral2014} is the state-of-the-art parametric model. Under full, clean data, it's excellent. Under sparse or noisy data, it exhibits the pathologies documented in Section~\ref{sec:sparse}. Our method complements rather than replaces SSVI: use SSVI when data is clean, CINN when data is sparse.

\textbf{Why not enforce convexity via parameterization?}

One could construct a neural network whose output \textit{by construction} satisfies no-arbitrage (e.g., via integration of positive functions). This is theoretically clean but practically limiting: such architectures are hard to train and often underfit. Our penalty approach trades theoretical purity for practical flexibility.

\textbf{Relationship to PINNs.}

Classical PINNs \citep{raissi2019} embed PDE \textit{equalities} in the loss. We adapt this paradigm to financial \textit{inequalities}. Calling our method ``physics-informed'' is a stretch; we use ``constraint-informed'' to be precise.

%------------------------------------------------------------------------------
\section{Conclusion}
\label{sec:conclusion}
%------------------------------------------------------------------------------

We have shown that the apparent tradeoff between flexible interpolation and arbitrage-freeness is avoidable under reasonable accuracy loss (4.3\%).

\textbf{The core contribution} is not a new arbitrage condition, but a training framework that makes enforcing existing conditions numerically stable, even under sparse data where parametric models fail.

\textbf{Main empirical findings:}
\begin{itemize}
    \item Under 60\% strike dropout, CINN achieves 0.04 bps EPP vs 3.21 bps for SVI
    \item Soft penalties ($\lambda \leq 0.1$) are insufficient; they reduce but do not eliminate exploitable arbitrage
    \item Constrained training \textit{reduces} initialization variance, making results more reproducible
\end{itemize}

\textbf{Honest limitations:}
\begin{itemize}
    \item No theoretical guarantee of constraint satisfaction; it works empirically
    \item $4\times$ slower than unconstrained methods
    \item Requires warmup scheduling to avoid gradient domination
\end{itemize}

\textbf{When to use this:} Sparse grids, noisy markets, regulatory requirements for arbitrage-freeness. \textbf{When not to:} Latency-critical applications, clean high-frequency data where SSVI suffices.

\textbf{Practical impact:} For SPX options under realistic sparsity conditions (40--60\% missing strikes), CINN reduces arbitrage to $<$0.05 bps while maintaining RMSE within 5\% of unconstrained MLPs. This makes it particularly suitable for single-stock options, emerging markets, and illiquid tenors where sparse grids are the norm.

\textbf{Future directions:} Extension to stochastic volatility surfaces (Heston, rough Bergomi), online learning for real-time updates, and theoretical characterization of minimal penalty weights for constraint satisfaction.

%------------------------------------------------------------------------------
% Appendix
%------------------------------------------------------------------------------

\appendix

\section{Counterexample: Non-Convexity}
\label{app:counterexample}

\begin{example}
Consider SVI smiles:
\begin{align}
    w_1(k) &= 0.04 + 0.1\left(-0.5k + \sqrt{k^2 + 0.01}\right) \\
    w_2(k) &= 0.04 + 0.3\left(0.5k + \sqrt{k^2 + 0.04}\right)
\end{align}
Both are admissible. Their average $w_{0.5} = 0.5 w_1 + 0.5 w_2$ has $g(k = 0.15) \approx -0.003 < 0$. Hence $\mathcal{A}$ is not convex.
\end{example}

\section{Why Not Projection?}
\label{app:projection}

A natural question: why not project onto the admissible set after training?

\textbf{Answer:} Because $\mathcal{A}$ is non-convex, no unique projection exists. Even if we could define one, computing $\Pi_{\mathcal{A}}(w)$ requires solving a constrained optimization problem \textit{per surface}---precisely what we're trying to avoid.

Some alternatives we considered:
\begin{itemize}
    \item \textbf{Iterative projection (ADMM-style):} Requires convexity for convergence guarantees.
    \item \textbf{Barrier methods:} Numerically unstable near constraint boundaries.
    \item \textbf{Architectures with built-in constraints:} E.g., integrating a positive function to guarantee monotonicity. These underfit in practice because they over-regularize.
\end{itemize}

Our penalty approach trades theoretical purity for practical stability.

%------------------------------------------------------------------------------
% Bibliography
%------------------------------------------------------------------------------

\bibliographystyle{abbrvnat}
\begin{thebibliography}{10}

\bibitem[Gatheral(2004)]{gatheral2004}
Gatheral, J. (2004).
A parsimonious arbitrage-free implied volatility parameterization.
\emph{Global Derivatives, Madrid}.

\bibitem[Gatheral and Jacquier(2014)]{gatheral2014}
Gatheral, J., \& Jacquier, A. (2014).
Arbitrage-free SVI volatility surfaces.
\emph{Quantitative Finance}, 14(1):59--71.

\bibitem[Hagan et al.(2002)]{hagan2002}
Hagan, P. et al. (2002).
Managing smile risk.
\emph{Wilmott Magazine}, 84--108.

\bibitem[Raissi et al.(2019)]{raissi2019}
Raissi, M. et al. (2019).
Physics-informed neural networks.
\emph{J.\ Computational Physics}, 378:686--707.

\bibitem[Ghadimi and Lan(2013)]{ghadimi2013}
Ghadimi, S., \& Lan, G. (2013).
Nonconvex stochastic optimization.
\emph{SIAM J.\ Optimization}, 23(4):2341--2368.

\bibitem[Breeden and Litzenberger(1978)]{breeden1978}
Breeden, D., \& Litzenberger, R. (1978).
Prices of state-contingent claims.
\emph{J.\ Business}, 51(4):621--651.

\bibitem[Fengler(2009)]{fengler2009}
Fengler, M. (2009).
Arbitrage-free smoothing of the implied volatility surface.
\emph{Quantitative Finance}, 9(4):417--428.

\end{thebibliography}

\end{document}
